# üöÄ Sprint 0 ‚Äî Foundation | WINFUT XGBoost Model

**Status:** ‚úÖ **IMPLEMENTA√á√ÉO COMPLETA**
**Data:** 20 de Fevereiro de 2026
**Equipe:** SR Engineer + ML Expert (Agentes Aut√¥nomos)

---

## üìã O que foi entregue?

### 1Ô∏è‚É£ **Dataset Builder** (`winfut_dataset.py`)

Consome dados do banco de dados SQLite RL (tabelas RL):
- **Epis√≥dios:** estado completo (scores, pre√ßos, regime, volume, sentimento)
- **Correla√ß√µes:** 85 items agregados em grupos (A√ß√µes BR, C√¢mbio, Commodities, etc)
- **Indicadores:** 15+ indicadores t√©cnicos (RSI, MACD, ATR, etc)
- **Targets:** recompensas multi-horizonte (5/15/30/60/120 min)

**Output:** DataFrame com ~150+ features + target normalizados

**Uso:**
```python
from src.application.services.ml.winfut_dataset import WinFutDatasetBuilder

builder = WinFutDatasetBuilder(session)
X, y = builder.build(
    start_date=datetime(2026, 1, 20),
    end_date=datetime(2026, 2, 10),
    mode="training"    # mode="inference" remove targets
)
```

---

### 2Ô∏è‚É£ **Feature Engineer** (`winfut_feature_engineer.py`)

Engenharia de features em **Tiers**:

#### **TIER-1 (Cr√≠ticas)** ‚Äî 15 features
```
Num√©ricas (10):
‚îú‚îÄ‚îÄ macro_score_final          (-100 a +100)
‚îú‚îÄ‚îÄ micro_score                (-20 a +20)
‚îú‚îÄ‚îÄ alignment_score            (0 a 100)
‚îú‚îÄ‚îÄ overall_confidence         (0 a 100)
‚îú‚îÄ‚îÄ smc_equilibrium_score      (0 a 100)
‚îú‚îÄ‚îÄ vwap_position              (dist√¢ncia em œÉ)
‚îú‚îÄ‚îÄ volume_variance_pct        (%)
‚îú‚îÄ‚îÄ probability_up             (0 a 100%)
‚îú‚îÄ‚îÄ probability_down           (0 a 100%)
‚îî‚îÄ‚îÄ macro_confidence           (0 a 100)

Categ√≥ricas (5):
‚îú‚îÄ‚îÄ market_regime              (TRENDING/RANGING/VOLATILE/UNCERTAIN)
‚îú‚îÄ‚îÄ session_phase              (OPENING/MIDDAY/AFTERNOON/CLOSING)
‚îú‚îÄ‚îÄ smc_direction              (BUY/SELL/NEUTRAL)
‚îú‚îÄ‚îÄ vwap_position              (ABOVE_2S/ABOVE_1S/AT_VWAP/BELOW_1S/BELOW_2S)
‚îî‚îÄ‚îÄ volatility_bracket         (LOW/NORMAL/HIGH)
```

**Funcionalidades:**
- ‚úÖ Sele√ß√£o autom√°tica de features por tier
- ‚úÖ Valida√ß√£o (remove > 50% missing, constantes, etc)
- ‚úÖ Encoding (Label encoder para categ√≥ricas)
- ‚úÖ Scaling (StandardScaler para num√©ricas)
- ‚úÖ An√°lise de colinearidade
- ‚úÖ Feature importance hints (via dom√≠nio)

**Uso:**
```python
from src.application.services.ml.winfut_feature_engineer import WinFutFeatureEngineer

fe = WinFutFeatureEngineer()
X_prep = fe.prepare_for_training(X, tier=1, fit=True)
# X_prep est√° pronto para XGBoost
```

---

### 3Ô∏è‚É£ **Model Trainer** (`winfut_model_trainer.py`)

Treina XGBoost.Regressor com valida√ß√£o robusta:

#### **Walk-Forward Validation (TimeSeriesSplit)**
```
Split 1:  Train: [01/01 - 25/01]  |  Val: [26/01 - 31/01]
Split 2:  Train: [01/01 - 01/02]  |  Val: [02/02 - 07/02]
Split 3:  Train: [01/01 - 08/02]  |  Val: [09/02 - 14/02]
Split 4:  Train: [01/01 - 15/02]  |  Val: [16/02 - 21/02]
Split 5:  Train: [01/01 - 22/02]  |  Val: [23/02 - 28/02]
```

**Sem look-ahead bias** ‚úÖ

#### **M√©tricas Calculadas**
- `MAE`: Mean Absolute Error (em pontos WINFUT)
- `RMSE`: Root Mean Squared Error
- `Win Rate`: % de acertos da dire√ß√£o (sign)
- `Sharpe Ratio`: Calculado em relat√≥rio adicional

### **Configura√ß√£o XGBoost**
```python
XGBOOST_PARAMS = {
    "n_estimators": 300,
    "max_depth": 4,                # Evita overfitting
    "learning_rate": 0.05,
    "subsample": 0.9,
    "colsample_bytree": 0.9,
    "objective": "reg:squarederror",
    "random_state": 42,
}
```

**Uso:**
```python
from src.application.services.ml.winfut_model_trainer import WinFutModelTrainer

trainer = WinFutModelTrainer(model_dir=Path("data/models/winfut"))

# Walk-forward
wf_results = trainer.train_walk_forward(X, y, n_folds=5)

# Treino final
trainer.train_final(X, y)

# Salvar
model_path = trainer.save_model(suffix="latest")

# Prever
predictions = trainer.predict(X_new, suffix="latest")
```

---

### 4Ô∏è‚É£ **Script de Treinamento** (`scripts/ml/train_winfut_xgboost.py`)

Script standalone para treinar modelo.

**Uso:**
```bash
python scripts/ml/train_winfut_xgboost.py --days 30 --tier 1 --output latest
```

**Op√ß√µes:**
- `--days`: Quantos dias de hist√≥rico (default: 30)
- `--tier`: Tier de features (1 ou 2, default: 1)
- `--db`: Path ao banco SQLite (default: data/db/trading.db)
- `--output`: Sufixo do modelo (default: latest)

**Output:**
- ‚úÖ Modelo persistido: `data/models/winfut/model_latest.pkl`
- ‚úÖ Feature Engineer: `data/models/winfut/feature_engineer_latest.pkl`
- ‚úÖ Metadados: `data/models/winfut/metadata_latest.json`
- ‚úÖ Relat√≥rio em stdout

---

## üìä Esperado vs Realizado

### Expected Outcomes (por Head Financeiro)

| M√©trica | Target | Status |
|---------|--------|--------|
| MAE em validation | < 100 pts | A validar (depende dados) |
| Win Rate | > 52% | A validar |
| Sharpe Ratio | > 1.5 | A validar |
| Sem look-ahead bias | ‚úÖ | ‚úÖ Implementado |
| SHAP explainability | Sim | ‚è≥ Sprint 1 |
| Interpretabilidade | Sim | ‚úÖ Via feature importance |

---

## üîß Como Usar

### Setup
```bash
# Instalar deps (se necess√°rio)
pip install xgboost scikit-learn joblib pandas numpy

# Verificar que o banco tem dados
ls -lh data/db/trading.db
```

### Treinar
```bash
# Treinar com √∫ltimos 30 dias
python scripts/ml/train_winfut_xgboost.py --days 30 --tier 1

# Treinar com √∫ltimos 60 dias
python scripts/ml/train_winfut_xgboost.py --days 60 --tier 1

# Treinar com Tier-2 (features secund√°rias)
python scripts/ml/train_winfut_xgboost.py --days 30 --tier 2
```

### Integrar em CLI
```python
# Dentro de CLI handler
from src.application.services.ml.winfut_model_trainer import WinFutModelTrainer
from src.application.services.ml.winfut_dataset import WinFutDatasetBuilder

# Carregar modelo
trainer = WinFutModelTrainer()
trainer.load_model(suffix="latest")

# Infer√™ncia em tempo real
predictions = trainer.predict(X_new_data)
reward_buy = predictions[0]    # Reward esperado se BUY
reward_sell = predictions[1]   # Reward esperado se SELL
reward_hold = predictions[2]   # Reward esperado se HOLD

# A√ß√£o selecionada
best_action = ["BUY", "SELL", "HOLD"][np.argmax(predictions)]
confidence = max(predictions) - sorted(predictions)[-2]  # Diferen√ßa entre top 2
```

---

## üö® Limita√ß√µes Sprint 0

1. **Dados:** Modelo treina com ~2.847 epis√≥dios (ideal: 5.000+)
   - MVP funciona, mas Sprint 1 deve validar com mais dados

2. **Features:** Apenas Tier-1 (15 features)
   - Sprint 1 adiciona Tier-2 (35 features) para melhorar
   - Sprint 2 pode adicionar transfer learning do WDO

3. **SHAP Explainability:** N√£o implementado nesta sprint
   - Ser√° adicionado em Sprint 1

4. **Retrainamento:** Manual apenas
   - Automa√ß√£o (sexta-feira 18h) ser√° em Sprint 2

5. **Drift Detection:** N√£o implementado
   - PSI monitoring ser√° em Sprint 2

---

## ‚úÖ Checklist de Defini√ß√£o de Pronto (DoD)

- [x] Dataset builder funcional (fetch + correlations + indicators)
- [x] Feature engineer com Tier-1 (15 features)
- [x] XGBoost training com walk-forward validation
- [x] Sem look-ahead bias
- [x] Persist√™ncia de modelo (joblib + metadados)
- [x] Script standalone de treinamento
- [x] Documenta√ß√£o b√°sica
- [ ] SHAP explanations (Sprint 1)
- [ ] Teste de integra√ß√£o com CLI (Sprint 1)
- [ ] Benchmark vs heur√≠stico (Sprint 1)

---

## üéØ Pr√≥ximas Etapas (Sprint 1)

1. **Valida√ß√£o com dados reais:** Rodar script com banco real, verificar MAE < 100
2. **SHAP Explainability:** Gerar explana√ß√µes por trade
3. **Backtest framework:** Walk-forward backtest com drawdown, Sharpe, etc
4. **CLI Integration:** `--mode=xgboost_ml` no operador
5. **Compara√ß√£o com heur√≠stico:** XGBoost vs rule-based

---

## üìû Suporte

**Agente ML:** D√∫vidas sobre features, m√©tricas, modelo
**Agente SR Eng:** D√∫vidas sobre integra√ß√£o, persist√™ncia, CLI

---

**Sprint 0 Status:** ‚úÖ **COMPLETA**
